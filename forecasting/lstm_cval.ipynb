{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT IF ON REMOTE JUPYTER\n",
    "# !pip install plotly pandas protobuf==3.20.0 tensorflow==2.6.2 scikit-learn numpy"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras import Input, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.optimizers import  Nadam\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from keras.layers import LeakyReLU\n",
    "from data_util_common import canopy_dataset, train_val_test_split\n",
    "from lstm_util import prepare_data, evaluate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da266e7ffad9ab96"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e30d2c6cc44c6f7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_model(input_shape, weights):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(Bidirectional(LSTM(168, return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(72, return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(48, return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(24, return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.add(LeakyReLU())\n",
    "   \n",
    "    if weights:\n",
    "        model.set_weights(weights)\n",
    "\n",
    "    model.compile(optimizer=Nadam(learning_rate=0.0001), loss=\"mae\")\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8b314716fb763d4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    data, label = canopy_dataset()\n",
    "    split_idx = train_val_test_split(pd.to_datetime(data.index), [80, 20])\n",
    "    train_val_size = split_idx[0]\n",
    "    data = data.iloc[:train_val_size, :]\n",
    "    \n",
    "    # scale data\n",
    "    numeric_features=['Irradiance_1_Wm2']\n",
    "    features = [label] + numeric_features \n",
    "    \n",
    "    data = data[features]\n",
    "    \n",
    "    print(data.columns)\n",
    "    label_idx = list(data.columns).index(label)\n",
    "    print(label_idx)\n",
    "    T = 24\n",
    "    past = T * 7\n",
    "    future = T\n",
    "    step = 1\n",
    "    batch_size = 512\n",
    "    sequence_length = int(past / step)\n",
    "\n",
    "    X = [data.iloc[i:i+T, :] for i in range(0, len(data.index)-T, T)]\n",
    "    timestamp = [data.index[i:i+T] for i in range(0, len(data.index)-T, T)]    \n",
    "    mae = []\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "        print(f\"Fold {i} - TRAIN DAYS {len(train_index)} TEST DAYS {len(test_index)}\")\n",
    "        train = np.asarray([X[t] for t in train_index])\n",
    "        train = train.reshape((T * len(train_index), len(features)))\n",
    "        \n",
    "        names = dict()\n",
    "        for k in range(train.shape[1]):\n",
    "            names[k] = features[k]\n",
    "            \n",
    "        train = pd.DataFrame(train).rename(columns=names)\n",
    "        train_timestamp = np.asarray([timestamp[t] for t in train_index])\n",
    "        train_timestamp = train_timestamp.reshape((T * len(train_timestamp), 1))\n",
    "        train_timestamp = pd.to_datetime([x[0] for x in train_timestamp], format='%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        pipeline=ColumnTransformer([\n",
    "            ('label', MinMaxScaler(), [label]),\n",
    "            ('num', MinMaxScaler(), numeric_features),\n",
    "        ], remainder='passthrough')\n",
    "        \n",
    "        train=pipeline.fit_transform(train)\n",
    "\n",
    "        # temp = pd.DataFrame(train)\n",
    "        # temp.index = train_timestamp\n",
    "        # temp.to_csv(f\"lstm/cval/{i}_train.csv\")\n",
    "        \n",
    "        split = train_val_test_split(train_timestamp, percentage=[70, 30])\n",
    "        val = train[split[0]:, :]\n",
    "        val_size = len(val)\n",
    "        train = train[:split[0], :]\n",
    "        train_size = len(train)\n",
    "        \n",
    "        test = np.asarray([X[t] for t in test_index])\n",
    "        test = test.reshape((T * len(test_index), len(features)))\n",
    "        test = pd.DataFrame(test).rename(columns=names)\n",
    "        test = pipeline.transform(test)\n",
    "        test_size = len(test)\n",
    "\n",
    "        test_timestamp = np.asarray([timestamp[t] for t in test_index])\n",
    "        test_timestamp = test_timestamp.reshape((T * len(test_index), 1))\n",
    "        test_timestamp = pd.to_datetime([x[0] for x in test_timestamp], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        print(f\"TRAIN {len(train)} - VAL {len(val)} - TEST {len(test)}\")\n",
    "        \n",
    "        # PREPARE DATA ---------------------------------------------------------------------------------------------------\n",
    "        # TRAIN\n",
    "        dataset_train = prepare_data(train, 0, train_size-past, past, train_size, sequence_length, 1, batch_size, label_idx)\n",
    "        \n",
    "        # VAL\n",
    "        dataset_val = prepare_data(val, 0, val_size-past, past, val_size, sequence_length, 1, batch_size, label_idx)\n",
    "        \n",
    "        # TEST\n",
    "        dataset_test = prepare_data(test, 0, test_size, past, test_size, sequence_length, 1, batch_size, label_idx)\n",
    "\n",
    "        for batch in dataset_train.take(1):\n",
    "            inputs, targets = batch\n",
    "\n",
    "        print(f\"Input shape:  {inputs.numpy().shape}\")\n",
    "        print(f\"Target shape: {targets.numpy().shape}\")\n",
    "        \n",
    "        checkpoint_filepath = f'lstm/cval/checkpoint_{k}.h5'\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, \n",
    "                            monitor=\"val_loss\",\n",
    "                            save_weights_only = True, \n",
    "                            save_best_only=True, verbose=0)\n",
    "\n",
    "        model = create_model((inputs.shape[1], inputs.shape[2]), None)\n",
    "        \n",
    "        history = model.fit(\n",
    "            dataset_train,\n",
    "            epochs=1000,\n",
    "            validation_data=dataset_val,\n",
    "            shuffle=False,\n",
    "            callbacks=[EarlyStopping(monitor=\"val_loss\", patience=30, min_delta=0.01),\n",
    "                      checkpoint\n",
    "                      ],\n",
    "            verbose=1\n",
    "        )\n",
    "         \n",
    "        model.load_weights(checkpoint_filepath)\n",
    "        \n",
    "        days = int((test_size-past)/T)\n",
    "        print(f\"DAYS {days}\")\n",
    "        results = evaluate(dataset_test, model, days, pipeline.named_transformers_['label'])\n",
    "        results.index = test_timestamp[past:]\n",
    "        results.to_csv(f\"lstm/cval/cval_res_{i}.csv\")\n",
    "        mae.append(mean_absolute_error(results['y_true'], results['y_pred']))\n",
    "    \n",
    "    print(\"MAE: {}\".format(np.mean(mae)))\n",
    "\n",
    "    with open('lstm/lstm_cavl_mae.npy', 'wb') as f:\n",
    "        np.save(f, mae)\n",
    "\n",
    "    fig = px.box(np.asarray(mae))\n",
    "    fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e140df3d206203dc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
